"""
Copyright (c) 2025 by Zhenhui Yuan. All right reserved.
FilePath: /brain-mix/nlp/knowledges/extractive/auto_choice_params.py
Author: yuanzhenhui
Date: 2025-10-27 00:25:37
LastEditTime: 2025-10-29 21:16:57
"""

import optuna
import numpy as np
from tqdm import tqdm
from sentence_transformers import SentenceTransformer, util
import re
import os
import sys

project_dir = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
sys.path.append(os.path.join(project_dir, 'utils'))

from thirdparty.silicon_util import SiliconUtil
from persistence.elastic_util import ElasticUtil
import const_util as CU
from yaml_util import YamlUtil
from logging_util import LoggingUtil
logger = LoggingUtil(os.path.basename(__file__).replace(".py", ""))

from content_compressor import ContentCompressor

es = ElasticUtil()

class AutoChoiceParams:
    
    def __init__(self):
        self.api = SiliconUtil()
        
        self.model_cnf = os.path.join(project_dir, 'resources', 'config', CU.ACTIVATE, 'nlp_cnf.yml')
        model_cnf = YamlUtil(self.model_cnf)
        self.model_name = model_cnf.get_value('models.compress.path')
        self.device = model_cnf.get_value('models.compress.device')
        
        self.utils_cnf = os.path.join(project_dir, 'resources', 'config', CU.ACTIVATE, 'utils_cnf.yml')
        utils_cnf = YamlUtil(self.utils_cnf)
        self.compress_content_param = utils_cnf.get_value('silicon.agent.compress_content')
        
        logger.info(f"Loading model: {self.model_name}")
        self.shared_model = SentenceTransformer(
            model_name_or_path=self.model_name, 
            device=self.device
        )
        logger.info("Model loaded successfully!")

    def semantic_similarity_score(self, original, summary):
        """è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†æ•°"""
        # å¦‚æœæ‘˜è¦ä¸ºç©ºï¼Œè¿”å›0.0
        if not summary:
            return 0.0
        try:
            # ä½¿ç”¨å…±äº«æ¨¡å‹å¯¹åŸå§‹æ–‡æœ¬è¿›è¡Œç¼–ç 
            emb1 = self.shared_model.encode([original], convert_to_tensor=True)
            # ä½¿ç”¨å…±äº«æ¨¡å‹å¯¹æ‘˜è¦æ–‡æœ¬è¿›è¡Œç¼–ç 
            emb2 = self.shared_model.encode([summary], convert_to_tensor=True)
            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
            sim = float(util.cos_sim(emb1, emb2)[0][0])
            # è®¡ç®—æ‘˜è¦ä¸åŸå§‹æ–‡æœ¬çš„é•¿åº¦æ¯”ä¾‹
            ratio = len(summary) / max(len(original), 1)
            # è®¡ç®—é•¿åº¦æ¯”ä¾‹çš„æƒ©ç½šå€¼
            penalty = abs(ratio - 0.5)
            # è¿”å›æœ€ç»ˆçš„è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†æ•°
            return max(0, sim * (1 - penalty))
        except Exception as e:
            # æ•è·å¼‚å¸¸å¹¶è®°å½•é”™è¯¯æ—¥å¿—
            logger.error(f"Semantic similarity calculation failed: {e}")
            # è¿”å›0.0ä½œä¸ºé»˜è®¤å€¼
            return 0.0

    def objective(self, trial, samples):
        """Optuna ç›®æ ‡å‡½æ•°"""
        
        # è°ƒä¼˜å‚æ•°ç©ºé—´
        params = {
            "compression_ratio": trial.suggest_float("compression_ratio", 0.3, 0.7),  # å‹ç¼©æ¯”ä¾‹
            "lambda_mmr": trial.suggest_float("lambda_mmr", 0.3, 0.9),  # MMRç®—æ³•å‚æ•°
            "position_weight": trial.suggest_float("position_weight", 0.0, 0.3),  # ä½ç½®æƒé‡
            "named_entity_weight": trial.suggest_float("named_entity_weight", 0.0, 0.5),  # å‘½åå®ä½“æƒé‡
            "number_weight": trial.suggest_float("number_weight", 0.0, 0.5),  # æ•°å­—æƒé‡
            "length_weight": trial.suggest_float("length_weight", 0.0, 0.3),  # é•¿åº¦æƒé‡
        }

        # åˆå§‹åŒ–å†…å®¹å‹ç¼©å™¨
        compressor = ContentCompressor(
            sentence_length_limit=400,  # å¥å­é•¿åº¦é™åˆ¶
            prefilter_ratio=0.7,  # é¢„è¿‡æ»¤æ¯”ä¾‹
            max_sentences=15  # æœ€å¤§å¥å­æ•°é‡
        )

        # åˆå§‹åŒ–åˆ†æ•°åˆ—è¡¨å’Œæ—©åœå‚æ•°
        scores = []
        patience, no_improve, best_score = 5, 0, -np.inf  # æ—©åœå‚æ•°

        # éå†æ ·æœ¬
        for text in tqdm(samples, desc=f"Trial {trial.number}", leave=False, disable=True):
            try:
                score_str = None
                # å‹ç¼©æ–‡æœ¬ç”Ÿæˆæ‘˜è¦
                summary = compressor.compress_text(text, **params)
                
                # è·³è¿‡ç©ºæ‘˜è¦
                if not summary or len(summary.strip()) == 0:
                    continue
                
                # LLM è¯„åˆ†
                prompt = f"""
                è¯·å¯¹ä»¥ä¸‹æ‘˜è¦å‹ç¼©è´¨é‡è¿›è¡Œè¯„åˆ†ã€‚

                ã€åŸæ–‡ã€‘
                {text}...

                ã€æ‘˜è¦ã€‘
                {summary}

                è¯·ä»ä»¥ä¸‹è§’åº¦ç»¼åˆæ‰“åˆ†ï¼ˆ1~10åˆ†ï¼‰ï¼š
                1. ä¿¡æ¯ä¿çœŸåº¦
                2. é€»è¾‘è¿è´¯æ€§
                3. å‹ç¼©æ•ˆæœ

                æ³¨æ„ï¼šåªè¾“å‡ºä¸€ä¸ªæ•°å­—åˆ†æ•°ï¼ˆå¦‚ 8.5ï¼‰ï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚
                """
                counter = 0
                # æœ€å¤šå°è¯•3æ¬¡è·å–LLMè¯„åˆ†
                while True and counter < 3:
                    score_str = self.api.chat_with_sync(self.compress_content_param, prompt)
                    if score_str:
                        break
                    else:
                        counter += 1
                    
                if score_str:
                    # æ¸…ç†è¯„åˆ†å­—ç¬¦ä¸²
                    score_str = re.sub(r'[^\d.]', '', score_str)
                    if score_str and score_str.replace('.', '', 1).isdigit():
                        llm_score = float(score_str)
                        # é™åˆ¶èŒƒå›´
                        llm_score = max(1.0, min(10.0, llm_score))
                        
                        # è®¡ç®—è¯­ä¹‰ç›¸ä¼¼åº¦åˆ†æ•°
                        sss_score = self.semantic_similarity_score(text, summary)
                        
                        # è®¡ç®—ç»¼åˆå¾—åˆ†
                        final_score = sss_score * 5.0 + llm_score * 0.5  # å½’ä¸€åŒ–åˆ° 0-10
                        scores.append(final_score)
                        
                        # ç®€æ˜“æ—©åœé€»è¾‘
                        if final_score > best_score:
                            best_score = final_score
                            no_improve = 0
                        else:
                            no_improve += 1
                            if no_improve >= patience:
                                break
                            
            except Exception as e:
                logger.error(f"Error in trial {trial.number}: {str(e)[:100]}")
                continue

        # å¦‚æœæ²¡æœ‰æœ‰æ•ˆåˆ†æ•°ï¼Œè¿”å›0.0
        if not scores:
            logger.warning(f"Trial {trial.number} got no valid scores!")
            return 0.0
        
        # è®¡ç®—å¹³å‡åˆ†æ•°å¹¶è®°å½•æ—¥å¿—
        avg_score = np.mean(scores)
        logger.info(f"Trial {trial.number} | Score={avg_score:.4f} | Params={params}")
        return avg_score

    def run_optimization(self, texts, n_trials=50):
        logger.info("Starting Optuna parameter optimization...")
        logger.info(f"Total samples: {len(texts)}, Trials: {n_trials}")
        
        study = optuna.create_study(direction="maximize")
        func = lambda trial: self.objective(trial, texts)
        study.optimize(
            func, 
            n_trials=n_trials, 
            n_jobs=1,  # å¿…é¡»ä½¿ç”¨å•è¿›ç¨‹
            show_progress_bar=True
        )

        logger.info("\n" + "="*50)
        logger.info("ğŸ† æœ€ä¼˜å‚æ•°é…ç½®:")
        for k, v in study.best_params.items():
            logger.info(f"  {k}: {v:.4f}")
        logger.info(f"  æœ€ä½³å¾—åˆ†: {study.best_value:.4f}")
        logger.info("="*50)
        
        return study.best_params

if __name__ == "__main__":
    docs_list = []
    acp = AutoChoiceParams()
    best_params = acp.run_optimization(docs_list, n_trials=10)
    logger.info("\næœ€ç»ˆæœ€ä¼˜å‚æ•°:")
    logger.info(best_params)